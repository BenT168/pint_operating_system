\documentclass{article}

\usepackage{fullpage}
\usepackage{listings}
\usepackage{color}

\setlength{\parskip}{0.5em}

\definecolor{dkgreen}{rgb}{0,0.6,0}
\definecolor{gray}{rgb}{0.5,0.5,0.5}
\definecolor{mauve}{rgb}{0.58,0,0.82}

\lstset{
  language=C,
  aboveskip=3mm,
  belowskip=3mm,
  showstringspaces=false,
  columns=flexible,
  basicstyle={\small\ttfamily},
  numbers=none,
  numberstyle=\tiny\color{gray},
  breaklines=true,
  breakatwhitespace=true,
  tabsize=3
}

\title{Pintos Task 1: Scheduling Design Document}
\author{Group 07: Ben Sheng Tan, Adanna Akwataghibe, Mark Aduol, Alessio Incitti }

\begin{document}
\maketitle

\section{PRIORITY SCHEDULING}

\subsection{ DATA STRUCTURES}

\subsection*{A1: (5 marks) }

\textit{Copy here the declaration of each new or changed ‘struct’ or ‘struct’ member, global or static variable, ‘typedef’, or enumeration. Identify the purpose of each in 25 words or less.}
\\ \\
In thread.h, we added:
\begin{lstlisting}
    struct thread
      {
        /* TASK 1 : Priority Checking */
        int base_priority;                /* initial priority of thread */
        struct list_elem donation_thread; /* thread element that is donated */
        struct lock* lock_waiting;        /* lock that thread is waiting for */
        struct list threads_donated;      /* list of threads */

        ...
      };

\end{lstlisting}
\\
Purpose of each new addition:

\texttt{base\_priority}: The base priority of the thread, without taking priority donations into account.

\texttt{donation\_threads}: \texttt{list\_elem} for the donor threads list. The donation thread can be added to another threads's donations

\texttt{lock\_waiting}: Lock that this thread is waiting on.

\texttt{thread\_donated}:  If the \texttt{lock\_waiting} is not NULL, then the current thread is
     waiting for a particular lock. \texttt{thread\_donated} is the list of
     (different) threads which are also waiting for \texttt{lock\_waiting}. This list is ordered by the priority of the threads.


\subsection*{A2: (10 marks) }

\textit{Explain the data structure used to track priority donation. Give a diagram that illustrates a nested donation in your structure.}
\\ \\
Priority donation is tracked using \texttt{struct list thread\_donated}, which is part of each
\texttt{struct thread}. \texttt{thread\_donated} is ordered in increasing order of priority of the elements.
\\ \\
Suppose we have three locks L1, L2 and L3. Also, suppose we have four threads T1, T2, T3 and T4.
We have a list of threads:
\\ \\
List of T's : T1 - T2 - T3 - T4
\\ \\
And T1 has lock\_waiting =  L1
\\ \\
T2 has lock\_waiting  = L2
\\ \\
T3 has lock\_waiting =  L3
\\ \\
And finally, T4 is not waiting on any lock, so the lock\_waiting is set to NULL.
\\ \\
Map of threads and locks :
( T1, L1 )  - ( T2, L2 ) - ( T3, L3 ) - ( T4, NULL )
\\ \\
We have that
\\ \\
T3's threads\_donated = T1 , T2.
And its donated priority is the maximum of T3 ,T1 and T2.
\\ \\
T4's threads\_donated = T3.
And its donated priority is the maximum of T3 and T2.


\subsection{ALGORITHMS}

\subsubsection*{A3: (5 marks) }
\textit{How do you ensure that the highest priority thread waiting for a lock, semaphore, or condition variable wakes up first?}
\\ \\
For locks and semaphores, this is handled at the semaphore level, by ordering the waiters list by the priority of the threads. For condition variables, since each semaphore in the list of waiters has exactly one thread, it is ordered in increasing order of priority of the thread in each semaphore.
A thread is woken up by popping the first element off the semaphore's waiters list, and unblocking it, and for condition variables, the semaphore to call \texttt{sema\_up} on is also the first element in its waiters list.
\\\\
In sych.c,
\begin{lstlisting}
    void sema_up (struct semaphore *sema)
    {
      ...
      /* TASK 1: Tests the maximum priority: if the new thread has higher priority than the currently running thread then let the former run first. */
      if(!intr_context()) {
        check_max_priority();
      }
      intr_set_level (old_level);
    }
\end{lstlisting}
\\\\
In thread.c,
\begin{lstlisting}
    void check_max_priority(void)
    {
        if(list_empty(&ready_list)) {
            return;
        }

        struct thread* t = list_entry(list_front(&ready_list), struct thread, elem);

        if(intr_context()) {
            thread_ticks++;
            if(thread_current ()->priority < t->priority || (thread_ticks >= TIME_SLICE
                            && thread_current()-> priority == t->priority)) {
               intr_yield_on_return();
            }
            return;
        }

        if(thread_current()->priority < t->priority) {
         thread_yield();
        }
    }

\end{lstlisting}


\subsubsection*{A4: (5 marks) }
\textit{Describe the sequence of events when a call to \texttt{lock\_acquire()} causes a priority donation. How is nested donation handled?}
\\ \\
If the lock has a holder, the current thread's \texttt{lock\_waiting} is updated with that lock.
Its priority is then donated to the lock holder. If in priority donation mode, set thread as waiting for the lock and insert current's \texttt{donation\_thread} into list \texttt{threads\_donated}. This function also adds the donor thread to
the \texttt{donor\_threads} of the donate thread.
\\ \\
After calling \texttt{sema\_down}, the current thread's \texttt{wait\_lock} is reset to \texttt{NULL}.

\begin{lstlisting}
    void lock_acquire (struct lock *lock)
    {
      ...

      if(!thread_mlfqs && lock->holder != NULL) {
        thread_current()->lock_waiting = lock;
        list_insert_ordered(&lock->holder->threads_donated,
                    &thread_current()->donation_thread, &is_lower_priority, NULL);
      }

      sema_down (&lock->semaphore);
      thread_current()->lock_waiting = NULL;
      lock->holder = thread_current();
    }
\end{lstlisting}
\\ \\
To handle the nestled donation, \texttt{donate\_priority()} declare a new struct thread and lock for  its execution. This function checks to see if the current thread has a donee by
using the \texttt{lock\_waiting} field. If it does have one, that threads \texttt{threads\_donated}
is reordered using \texttt{update\_priority()}. This function updates priority member in thread struct with the effective priority (i.e. taking into account donations).

\begin{lstlisting}
    void donate_priority(void) {
      int depth = 0;
      struct thread *t = thread_current();
      struct lock *l = t->lock_waiting;
      while(l != NULL && depth < DEPTH_LIMIT) {
        depth++;

        if(l->holder == NULL) return;
        if(l->holder->priority >= t->priority) return;

        l->holder->priority = t->priority;
        t = l->holder;
        l = t->lock_waiting;
      }
    }

    void update_priority(void) {
      struct thread *t = thread_current();
      t->priority = t->base_priority;
      if(list_empty(&t->threads_donated)) {
        return;
      }
      struct thread *t2 = list_entry(list_front(&t->threads_donated),
                                   struct thread, donation_thread);

      if(t2->priority > t->priority) {
         t->priority = t2->priority;
       }
      }
\end{lstlisting}


\subsubsection*{A5: (5 marks) }
\textit{Describe the sequence of events when \texttt{lock\_release()} is called on a lock that a higher-priority thread is waiting for.}
\\ \\
If \texttt{thread\_mlfqs} returns false, call \texttt{remove\_from\_lock(lock)} on all elements of lock to remove the item from \texttt{threads\_donated} threads waiting for lock l.
\\ \\
Note that since the semaphores waiters list is ordered (as mentioned in A3) we know that the new owner of the lock will be the first element of this list. As such we donate the priority of all other waiters in the list to its first element.
\\ \\
After this \texttt{sema\_up} is called which unblocks the first element of the waiters list.
\\ \\
In thread.c, we added:
\begin{lstlisting}
    /* TASK 1: Removes from list threads_donated threads waiting for lock l */
    void remove_with_lock(struct lock* l) {
      struct list_elem* e = list_begin(&thread_current()->threads_donated);
      struct list_elem* next;
      while(e != list_end(&thread_current()->threads_donated)) {
        struct thread* t = list_entry(e, struct thread, donation_thread);
        next = list_next(e);
        if(t->lock_waiting == l) {
          list_remove(e);
        }
        e = next;
      }
    }
\end{lstlisting}
\\ \\
In synch.c, we added:
\begin{lstlisting}
    void lock_release (struct lock *lock)
    {
      ...
      //TASK 1
      if(!thread_mlfqs) {
        remove_with_lock(lock);
        update_priority();
      }
      sema_up (&lock->semaphore);
    }

\end{lstlisting}



\subsection{SYNCHRONIZATION}

\subsubsection*{A6: (5 marks) }
\textit{Describe a potential race in \texttt{thread\_set\_priority()} and explain how your implementation avoids it.  Can you use a lock to avoid this race?}
\\ \\
A potential race in \texttt{thread\_set\_priority()} is that in (line A6a) we have that the current thread is setting its base priority to new priority. And there could be an interrupt before we call \texttt{update\_priority()}, which would mean that the thread's base priority is not updated properly. We disable interrupts in order to avoid this race condition. We cannot use locks in this situation as the interrupt could still happen before \texttt{update\_priority()} is called.
\\ \\
In thread.c, we added:
\begin{lstlisting}
    void thread_set_priority (int new_priority)
    {
      /* Advanced scheduler mode makes no use of this function */
      if(thread_mlfqs) return;

      enum intr_level level = intr_disable();
      int priority_prev = thread_current()->priority;
      thread_current()->base_priority = new_priority;                                   (Line A6a)
      update_priority();

      if(priority_prev < thread_current()->priority) {
        donate_priority();
      }
      if (priority_prev > thread_current()->priority) {
        check_max_priority();
      }

      intr_set_level(level);
    }
\end{lstlisting}


\subsection{RATIONALE}

\subsubsection*{A7: (5 marks) }
\textit{Why did you choose this design?  In what ways is it superior to another design you considered?}
\\ \\
We chose to use interrupts most of the time, instead of locks because it made the code clearer and it was a good way to make sure that in a block of code which was updating a value of the thread, that only one thread would be running and we would not have any races.
The reason why we decided to used a priority-based sorted ready\_list is because it makes it much more efficient for the function check\_max\_priority to check against the list since it can be assumed that the front has the highest priority, therefore it requires constant time. However, a disadvantage to this is that insertion into the list has higher cost because list\_insert\_ordered is used instead of list\_push\_back, which in the worst case requires a comparison against every element of the list. We believe that this design is superior to a non-sorted ready\_list because it is overall more efficient and much clearer conceptually.

\section{ADVANCED SCHEDULER}

\subsection{DATA STRUCTURES}

\subsection*{B1: (5 marks) }

\textit{Copy here the declaration of each new or changed ‘struct’ or ‘struct’ member, global or static variable, ‘typedef’, or enumeration. Identify the purpose of each in 25 words or less.}
\\\\
In thread.h, we added:
\begin{lstlisting}
    struct thread
      {
        ...
        /* TASK 1: Advanced scheduling */
        int cpu_num;
        int nice;
        ...
        };
\end{lstlisting}
\\\\
In 'thread.c', we added:
\begin{lstlisting}
    static int load_avg;
\end{lstlisting}
 \\\\
Purpose of each new addition:

\texttt{int cpu\_num}: the recent CPU value of the current thread in fixed point.

\texttt{int nice}: niceness value of the current thread.

\texttt{int load\_avg}: the system's load average value in fixed point.


\subsection{ALGORITHMS}

\subsubsection*{B2: (5 marks) }
\textit{HSuppose threads A, B, and C have nice values 0, 1, and 2.  Each has a \texttt{recent\_cpu} value of 0.  Fill in the table below showing the scheduling decision and the priority and \texttt{recent\_cpu} values for each thread after each given number of timer ticks:}

\begin{table}[htb]
\centering
\begin{tabular}{llllllll}
\multirow{2}{*}{\begin{tabular}[c]{@{}c@{}}timer\\ ticks\end{tabular}} & \multicolumn{3}{c|}{recent\_cpu} & \multicolumn{3}{c|}{priority} & thread to run \\ \cline{2-8}
                                                                       & A         & B         & C       & A        & B        & C       &               \\ \hline
                                                                       0           & 0         & 0       & 0        & 63       & 61       & 59      & A             \\ \hline
                                                                       4           & 4         & 0       & 0        & 62       & 61       & 59      & A             \\ \hline
                                                                       8           & 8         & 0       & 0        & 61       & 61       & 59      & B             \\ \hline
                                                                       12          & 8         & 4       & 0        & 61       & 60       & 59      & A            \\ \hline
                                                                       16          & 12        & 4       & 0        & 60       & 60       & 59      & B             \\ \hline
                                                                       20          & 12        & 8       & 0        & 60       & 59       & 59      & A             \\ \hline
                                                                       24          & 16        & 8       & 0        & 59       & 59       & 59      & C             \\ \hline
                                                                       28          & 16        & 8       & 4        & 59       & 59       & 58      & B            \\ \hline
                                                                       32          & 16        & 12      & 4        & 59       & 58       & 58      & A             \\ \hline
                                                                       36          & 20        & 12      & 4        & 58       & 58       & 58      & C             \\ \hline
                                                                       \end{tabular}
\end{table}

\subsubsection*{B3: (5 marks) }
\textit{Did any ambiguities in the scheduler specification make values in the table uncertain?  If so, what rule did you use to resolve them?  Does this match the behaviour of your scheduler?}
\\ \\
They were some ambiguities in the scheduler specification. For example,it does not specify what happens what thread is supposed to run if multiple threads all have the same priority. We are not told which thread is supposed to run in this instance.
  \\\\
In order to solve this problem, we use both the Round Robin and FIFO(first in, first out) rules which is what our scheduler implements as well.
  \\\\
For the FIFO implementation, the \texttt{ready\_list} contains all the threads which are ready to run. So, if the scheduler needs to choose between multiple threads to run, it simply chooses the first thread in the \texttt{ready\_list}, which by default is the thread who has the lowest running time.
  \\\\
For the Round Robin implementation, if the current (running) thread has the same priority as a ready thread, and this priority also happens to be the highest priority, then when the current thread reaches the \texttt{TIME\_SLICE} (4 ticks), it continues running regardless.

\subsubsection*{B4: (5 marks) }
\textit{How is the way you divided the cost of scheduling between code inside and outside interrupt context likely to affect performance?}
\\ \\
Since the load average, cpu and priority of mlfqs all have to be calculated after a set amount of time. We are given that the load average and cpu have to be calculated every one second, and also the thread priority has to recalculated every 4 ticks. It is therefore neccessary to have these calculations in the timer interrupt handler. However, it would be better if the calculations were not done in the interrupt handler. This is because, the thread that is interrupted would have less running time and also stops the running of other interrupts . So with more threads that are interrupted, the more the performance is affected.

\subsection{RATIONALE}

\subsubsection*{B5: (5 marks) }
\textit{Briefly critique your design, pointing out advantages and disadvantages in your design choices.}
\\ \\
 Calculating the load average, the cpu and the derived thread priority in the
  timer interrupt handler will allow the scheduler to be more dynamic as it can
  keep up to date with what is happening every certain number of ticks (4 in this case).
  On the other hand this will severely slow down performance since the timer interrupt
  handler gets called constantly and therefore there is a large amount of computation
  executed frequently.
\\ \\
Another disadvantage is the lack of use of locks in our code, which in some cases could make it inefficient when running threads. Also it may have been better if the fixed point functions were implemented as macros rather than functions since we are only using the functions in the one file.


\subsubsection*{B6: (5 marks) }
\textit{The assignment explains arithmetic for fixed-point mathematics in detail, but it leaves it open to you to implement it.  Why did you decide to implement it the way you did?  If you created an abstraction layer for fixed-point mathematics, that is, an abstract data type and/or a set of functions or macros to manipulate fixed-point numbers, why did you do so?  If not, why not?S}
\\ \\
We created one header file for the implementations of fixed point arithmetic
  - fixedpointrealarith.h. We used functions which performed the calculations
  needed. We chose to implement it like this for the following reasons.
    - Easy to call the functions to calculate in thread.c
	- Each function name was given clearly for example \texttt{div\_x\_y} and \texttt{div\_x\_n}
	  where in each function name, x and y would represent fixed-point numbers
	  and n would represent an integer.
	- If for any reason, an error was made in the implementation of the function
      since we only wrote the calculations once, it was easy to change the offending
      function (since it was only in the .h file).

\end{document}
